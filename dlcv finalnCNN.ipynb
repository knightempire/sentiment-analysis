{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cbcd8d-c68e-430f-8f8f-42d579485067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65dc30d5-9c30-4d6f-a3f6-bffbb83dd79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Histogram Equalization\n",
    "def histogram_equalization(img):\n",
    "    return cv2.equalizeHist(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c962f146-2394-4586-bcd6-de5b2fb28a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Gaussian Blur\n",
    "def gaussian_blur(img, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(img, kernel_size, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b393a4ac-4a65-4393-871f-d66d507b041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Canny Edge Detection\n",
    "def canny_edge_detection(img, low_threshold=100, high_threshold=200):\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0c35ea-3a98-44f4-9c17-e2fd87b8105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image with all techniques\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply Histogram Equalization\n",
    "    img_eq = histogram_equalization(img)\n",
    "    \n",
    "    # Apply Gaussian Blur\n",
    "    img_blur = gaussian_blur(img_eq)\n",
    "    \n",
    "    # Apply Canny Edge Detection\n",
    "    img_edges = canny_edge_detection(img_blur)\n",
    "    \n",
    "    return img_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d298100-0e95-4b97-adab-adba19c8c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply PCA after preprocessing\n",
    "def apply_pca(images, n_components=100):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    flat_images = images.reshape(images.shape[0], -1)  # Flatten the images for PCA\n",
    "    pca_images = pca.fit_transform(flat_images)\n",
    "    print(f\"Original dimensions: {flat_images.shape}, Reduced dimensions: {pca_images.shape}\")\n",
    "    return pca_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da97ea0-002e-42f9-8e6e-e7ff9c3b51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "def load_and_preprocess_images(image_paths):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for path in image_paths:\n",
    "        img = preprocess_image(path)\n",
    "        img_resized = cv2.resize(img, (48, 48))  # Resize to 48x48 as required by the model\n",
    "        images.append(img_resized)\n",
    "        label = path.split(os.sep)[-2]  # Assuming label is part of the path\n",
    "        labels.append(label)\n",
    "    images = np.array(images)\n",
    "    labels = pd.get_dummies(labels).values  # One-hot encode labels\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce0bae0-c8df-4379-8817-8a4bea5ec028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image paths\n",
    "train_image_paths = glob.glob(os.path.join(\"dataset2\", \"train\", \"**\", \"*.jpg\"), recursive=True)\n",
    "test_image_paths = glob.glob(os.path.join(\"dataset2\", \"test\", \"**\", \"*.jpg\"), recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b669a22-f377-421e-b742-38a2cf63fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "train_images, train_labels = load_and_preprocess_images(train_image_paths)\n",
    "test_images, test_labels = load_and_preprocess_images(test_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ded821-5254-404c-9ae6-691d8fde1fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions: (28709, 2304), Reduced dimensions: (28709, 100)\n",
      "Original dimensions: (7178, 2304), Reduced dimensions: (7178, 100)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA for dimensionality reduction\n",
    "train_images_pca = apply_pca(train_images, n_components=100)\n",
    "test_images_pca = apply_pca(test_images, n_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cd9ff21-4039-4d0d-9ead-1e4bfd7b6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape images back to (batch, height, width, channels) format for CNN\n",
    "train_images_pca = train_images_pca.reshape(-1, 10, 10, 1)  # Reshape to (batch_size, height, width, channels)\n",
    "test_images_pca = test_images_pca.reshape(-1, 10, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3cf1fe-d753-463c-bb23-b4f3843da696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation with ImageDataGenerator\n",
    "image_generator = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Adjust brightness\n",
    "    rescale=1/255.0  # Rescale pixel values to [0, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffe2e05d-6d49-4432-8964-8911341d3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment and fit the model\n",
    "train_generator = image_generator.flow(train_images_pca, train_labels, batch_size=64)\n",
    "test_generator = image_generator.flow(test_images_pca, test_labels, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f323a185-ae27-492f-9530-b6897b24a567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model-building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tune the number of filters for each layer\n",
    "    model.add(Conv2D(hp.Int('conv1_filters', min_value=32, max_value=128, step=32), (3, 3), padding='same', input_shape=(10, 10, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(hp.Float('conv1_dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Conv2D(hp.Int('conv2_filters', min_value=64, max_value=256, step=64), (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(hp.Float('conv2_dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Tune the number of neurons in dense layers\n",
    "    model.add(Dense(hp.Int('dense_units', min_value=128, max_value=512, step=128), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dense_dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    # Tune the learning rate for the optimizer\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333c5d90-85ba-4de0-8ed2-2edeb9d5395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 01m 24s]\n",
      "val_accuracy: 0.25410977005958557\n",
      "\n",
      "Best val_accuracy So Far: 0.2566174566745758\n",
      "Total elapsed time: 00h 32m 08s\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with Keras Tuner\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=20,\n",
    "                        executions_per_trial=1,\n",
    "                        directory='hyperparam_tuning_code_final',\n",
    "                        project_name='emotion_classification_with_hyperparameter_final')\n",
    "\n",
    "# Early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "model_checkpoint = ModelCheckpoint('best_model_final_run_with_hp.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "tuner.search(train_generator,\n",
    "             validation_data=test_generator,\n",
    "             epochs=50,\n",
    "             callbacks=[early_stopping, reduce_lr, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452047a-e7c1-40c5-b09c-bfefc2576548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d918d0-ea14-478e-a08b-8c932fb97d3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03964bd-fb04-4d6f-ac42-90432d2e7334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36829207-50c5-4cc3-a05e-7fe1a9e9d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527b759-cab7-46b4-bdb9-440d1477ca98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9c62d-93f4-439b-848a-df83ec54bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
