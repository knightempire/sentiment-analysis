{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvvlV6eJMeZ5",
    "outputId": "c46f02d6-402f-414d-d114-8cad1d63bfa1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras import Model, layers, applications, optimizers, callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "def load_and_preprocess_data(data_path):\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"The file {data_path} does not exist.\")\n",
    "\n",
    "    data = pd.read_csv(data_path)\n",
    "    if data.empty:\n",
    "        raise ValueError(f\"The file {data_path} is empty.\")\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "        try:\n",
    "            pixel_data = row['pixels']\n",
    "            pixels = list(map(int, pixel_data.split(' ')))\n",
    "\n",
    "            if len(pixels) != 48 * 48:\n",
    "                print(f\"Skipping row {i}: Pixel data length is {len(pixels)} instead of 48x48.\")\n",
    "                continue\n",
    "\n",
    "            image = np.array(pixels).reshape(48, 48).astype(np.uint8)\n",
    "            image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "            X.append(image)\n",
    "            y.append(row['emotion'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {i}: {str(e)}\")\n",
    "\n",
    "    if not X or not y:\n",
    "        raise ValueError(\"No valid data found in the CSV file.\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    X = np.expand_dims(X, axis=-1)\n",
    "    X = np.repeat(X, 3, axis=-1)  # Convert grayscale to RGB\n",
    "    X = X / 255.0  # Normalize the pixel values\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Random Rotation\n",
    "def random_rotation(image):\n",
    "    return tf.image.rot90(image, k=tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "# Custom Random Cutout\n",
    "def random_cutout(image, mask_size=(40, 40)):\n",
    "    h, w = image.shape[0], image.shape[1]\n",
    "    mask_height, mask_width = mask_size\n",
    "\n",
    "    top = tf.random.uniform([], 0, h - mask_height, dtype=tf.int32)\n",
    "    left = tf.random.uniform([], 0, w - mask_width, dtype=tf.int32)\n",
    "\n",
    "    cutout = tf.ones((mask_height, mask_width, 3), dtype=image.dtype) * 0  # Black mask\n",
    "    mask = tf.image.pad_to_bounding_box(cutout, top, left, h, w)\n",
    "\n",
    "    return image * (1 - mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Data Augmentation and Preprocessing\n",
    "def preprocess_image(image, label):\n",
    "    if image.shape[-1] != 3:\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = random_rotation(image)\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "    image = tf.image.random_hue(image, max_delta=0.2)\n",
    "    image = random_cutout(image)\n",
    "\n",
    "    return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset with Batch Size\n",
    "def create_dataset(x, y, batch_size=32, is_training=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    if is_training:\n",
    "        dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "def build_model(num_classes, dropout_rate=0.5, dense_units=512):\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Unfreeze the last few layers of the base model\n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(dense_units, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 5us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 5s/step - accuracy: 0.4651 - loss: 2.0131 - val_accuracy: 0.6483 - val_loss: 3.6747 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.6479 - loss: 1.2472 - val_accuracy: 0.6483 - val_loss: 5.5249 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 5s/step - accuracy: 0.6382 - loss: 1.1878 - val_accuracy: 0.6483 - val_loss: 4.5051 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.7198 - loss: 0.9327 - val_accuracy: 0.7241 - val_loss: 2.2517 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.7867 - loss: 0.7208 - val_accuracy: 0.7172 - val_loss: 2.3493 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 6s/step - accuracy: 0.8145 - loss: 0.6366 - val_accuracy: 0.6414 - val_loss: 3.7634 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 6s/step - accuracy: 0.8541 - loss: 0.5390 - val_accuracy: 0.7379 - val_loss: 2.1111 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 6s/step - accuracy: 0.8212 - loss: 0.5650 - val_accuracy: 0.2759 - val_loss: 5.6502 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.8632 - loss: 0.5705 - val_accuracy: 0.7586 - val_loss: 3.5728 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 5s/step - accuracy: 0.8442 - loss: 0.4653 - val_accuracy: 0.8138 - val_loss: 4.2271 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5s/step - accuracy: 0.8794 - loss: 0.3751 - val_accuracy: 0.8069 - val_loss: 1.8883 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5s/step - accuracy: 0.9087 - loss: 0.3152 - val_accuracy: 0.7517 - val_loss: 2.2586 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 6s/step - accuracy: 0.9023 - loss: 0.3173 - val_accuracy: 0.8069 - val_loss: 1.6434 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5s/step - accuracy: 0.8492 - loss: 0.4649 - val_accuracy: 0.2897 - val_loss: 7.6282 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 6s/step - accuracy: 0.8892 - loss: 0.3559 - val_accuracy: 0.8897 - val_loss: 0.4912 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5s/step - accuracy: 0.9219 - loss: 0.2378 - val_accuracy: 0.7310 - val_loss: 1.5742 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.8907 - loss: 0.2654 - val_accuracy: 0.8414 - val_loss: 0.6643 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.9224 - loss: 0.2424 - val_accuracy: 0.8345 - val_loss: 0.8624 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9181 - loss: 0.2620 - val_accuracy: 0.8759 - val_loss: 0.9255 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5s/step - accuracy: 0.9083 - loss: 0.2501 - val_accuracy: 0.6414 - val_loss: 1.6584 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 6s/step - accuracy: 0.9374 - loss: 0.1948 - val_accuracy: 0.8759 - val_loss: 0.6165 - learning_rate: 2.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 6s/step - accuracy: 0.9714 - loss: 0.1118 - val_accuracy: 0.9103 - val_loss: 0.3451 - learning_rate: 2.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 6s/step - accuracy: 0.9833 - loss: 0.0681 - val_accuracy: 0.9103 - val_loss: 0.3216 - learning_rate: 2.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 6s/step - accuracy: 0.9729 - loss: 0.0773 - val_accuracy: 0.8966 - val_loss: 0.3121 - learning_rate: 2.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 6s/step - accuracy: 0.9844 - loss: 0.0581 - val_accuracy: 0.9103 - val_loss: 0.3679 - learning_rate: 2.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 5s/step - accuracy: 0.9690 - loss: 0.0818 - val_accuracy: 0.9172 - val_loss: 0.2830 - learning_rate: 2.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 6s/step - accuracy: 0.9765 - loss: 0.0806 - val_accuracy: 0.9034 - val_loss: 0.3072 - learning_rate: 2.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 6s/step - accuracy: 0.9947 - loss: 0.0395 - val_accuracy: 0.9172 - val_loss: 0.3013 - learning_rate: 2.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 6s/step - accuracy: 0.9883 - loss: 0.0599 - val_accuracy: 0.9103 - val_loss: 0.3037 - learning_rate: 2.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.9915 - loss: 0.0464 - val_accuracy: 0.9241 - val_loss: 0.3209 - learning_rate: 2.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.9772 - loss: 0.0636 - val_accuracy: 0.9103 - val_loss: 0.3304 - learning_rate: 2.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9915 - loss: 0.0276 - val_accuracy: 0.9103 - val_loss: 0.2979 - learning_rate: 4.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.9903 - loss: 0.0319 - val_accuracy: 0.9172 - val_loss: 0.2796 - learning_rate: 4.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.9957 - loss: 0.0388 - val_accuracy: 0.9241 - val_loss: 0.2820 - learning_rate: 4.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5s/step - accuracy: 0.9955 - loss: 0.0349 - val_accuracy: 0.9241 - val_loss: 0.2732 - learning_rate: 4.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9901 - loss: 0.0384 - val_accuracy: 0.9310 - val_loss: 0.2663 - learning_rate: 4.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9933 - loss: 0.0364 - val_accuracy: 0.9310 - val_loss: 0.2595 - learning_rate: 4.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 5s/step - accuracy: 0.9917 - loss: 0.0303 - val_accuracy: 0.9310 - val_loss: 0.2595 - learning_rate: 4.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.9946 - loss: 0.0263 - val_accuracy: 0.9310 - val_loss: 0.2645 - learning_rate: 4.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 5s/step - accuracy: 0.9941 - loss: 0.0318 - val_accuracy: 0.9241 - val_loss: 0.2697 - learning_rate: 4.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9950 - loss: 0.0199 - val_accuracy: 0.9379 - val_loss: 0.2570 - learning_rate: 4.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.9877 - loss: 0.0360 - val_accuracy: 0.9379 - val_loss: 0.2509 - learning_rate: 4.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.9928 - loss: 0.0247 - val_accuracy: 0.9310 - val_loss: 0.2469 - learning_rate: 4.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.9990 - loss: 0.0158 - val_accuracy: 0.9310 - val_loss: 0.2459 - learning_rate: 4.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9888 - loss: 0.0395 - val_accuracy: 0.9310 - val_loss: 0.2535 - learning_rate: 4.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 5s/step - accuracy: 0.9929 - loss: 0.0271 - val_accuracy: 0.9310 - val_loss: 0.2481 - learning_rate: 4.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 5s/step - accuracy: 0.9948 - loss: 0.0222 - val_accuracy: 0.9310 - val_loss: 0.2449 - learning_rate: 4.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.9963 - loss: 0.0221 - val_accuracy: 0.9310 - val_loss: 0.2419 - learning_rate: 4.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 5s/step - accuracy: 0.9982 - loss: 0.0192 - val_accuracy: 0.9241 - val_loss: 0.2484 - learning_rate: 4.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 5s/step - accuracy: 0.9986 - loss: 0.0165 - val_accuracy: 0.9241 - val_loss: 0.2500 - learning_rate: 4.0000e-05\n",
      "Training Time: 4870.41 seconds\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 712ms/step - accuracy: 0.9297 - loss: 0.2399\n",
      "Evaluation Time: 4.39 seconds\n",
      "Test Accuracy: 93.37%\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       1.00      0.58      0.74        12\n",
      "     Disgust       1.00      1.00      1.00         9\n",
      "        Fear       0.67      0.40      0.50         5\n",
      "       Happy       0.85      1.00      0.92        11\n",
      "         Sad       0.33      0.25      0.29         4\n",
      "    Surprise       1.00      1.00      1.00        18\n",
      "     Neutral       0.95      0.99      0.97       122\n",
      "\n",
      "    accuracy                           0.93       181\n",
      "   macro avg       0.83      0.75      0.77       181\n",
      "weighted avg       0.93      0.93      0.93       181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Main Training Function\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    batch_size = 32\n",
    "    dropout_rate = 0.5\n",
    "    dense_units = 512\n",
    "    initial_learning_rate = 0.001\n",
    "    epochs = 50\n",
    "\n",
    "    # Load and preprocess data\n",
    "    data_path = 'ckextended.csv'\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        X, y = load_and_preprocess_data(data_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {str(e)}\")\n",
    "        return\n",
    "\n",
    "    # Define emotion dictionary\n",
    "    emotion_dict = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "    # Filter out any samples where the label is not in the range 0-6\n",
    "    valid_indices = [i for i, label in enumerate(y) if label in emotion_dict]\n",
    "    X = np.array([X[i] for i in valid_indices])\n",
    "    y = np.array([y[i] for i in valid_indices])\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = create_dataset(X_train, y_train, batch_size=batch_size)\n",
    "    val_dataset = create_dataset(X_val, y_val, batch_size=batch_size, is_training=False)\n",
    "    test_dataset = create_dataset(X_test, y_test, batch_size=batch_size, is_training=False)\n",
    "\n",
    "    # Build model\n",
    "    num_classes = len(emotion_dict)\n",
    "    model = build_model(num_classes, dropout_rate=dropout_rate, dense_units=dense_units)\n",
    "\n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # Train model\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=50, callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "    end_time = time.time()\n",
    "    print(f\"Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # Plot training history\n",
    "    plot_history(history)\n",
    "\n",
    "    # Measure evaluation time\n",
    "    start_time = time.time()\n",
    "    test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "    end_time = time.time()\n",
    "    print(f\"Evaluation Time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "    # Generate predictions for confusion matrix\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for images, labels in test_dataset:\n",
    "        predictions = model.predict(images)\n",
    "        y_pred.extend(np.argmax(predictions, axis=1))\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_true, y_pred, list(emotion_dict.values()))\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=list(emotion_dict.values())))\n",
    "\n",
    "    # Save the final model\n",
    "    model.save('final_model.keras')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix using true and predicted labels.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like of shape (n_samples,), Ground truth (correct) target values.\n",
    "    - y_pred: array-like of shape (n_samples,), Estimated targets as returned by a classifier.\n",
    "    - labels: list of string labels for the confusion matrix.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m emotion_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAnger\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDisgust\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHappy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurprise\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNeutral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFear\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming y_true and y_pred have been populated after model predictions\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plot_confusion_matrix(\u001b[43my_true\u001b[49m, y_pred, emotion_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "emotion_labels = ['Anger', 'Disgust', 'Happy', 'Sad', 'Surprise', 'Neutral', 'Fear']\n",
    "# Assuming y_true and y_pred have been populated after model predictions\n",
    "plot_confusion_matrix(y_true, y_pred, emotion_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
